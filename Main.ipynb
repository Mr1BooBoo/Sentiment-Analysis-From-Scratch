{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "QCIBottlOriw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xiH9dfIjOiNc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and arranging data"
      ],
      "metadata": {
        "id": "r3w8UNIxOtmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/train_dataset.json'\n",
        "with open(file_path, 'r') as json_file:\n",
        "    dataset = json.load(json_file)\n",
        "\n",
        "main_dict = dataset[\"conversation\"]\n",
        "\n",
        "\n",
        "#labels contains emotions\n",
        "#data contains the text\n",
        "\n",
        "initial_labels = []\n",
        "og_data = []\n",
        "\n",
        "for sub_dict in main_dict.values():\n",
        "    for inner_dict in sub_dict:\n",
        "        emotion = inner_dict.get('emotion')\n",
        "        text = inner_dict.get('text')\n",
        "        initial_labels.append(emotion)\n",
        "        og_data.append(text)\n",
        "\n",
        "\n",
        "\n",
        "# Create a mapping from emotions to numbers\n",
        "emotion_mapping = {\n",
        "    \"neutral\": 0,\n",
        "    \"joy\": 1,\n",
        "    \"surprise\": 2,\n",
        "    \"disgust\": 3,\n",
        "    \"sadness\": 4,\n",
        "    \"anger\": 5,\n",
        "    \"fear\": 6\n",
        "}\n",
        "\n",
        "labels = [emotion_mapping[emotion] for emotion in initial_labels]\n",
        "\n",
        "\n",
        "del file_path,json_file,dataset,emotion,text,main_dict,sub_dict,inner_dict,initial_labels,emotion_mapping"
      ],
      "metadata": {
        "id": "bpRRTKkhOoWF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "rtJ6AmBPOyVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXZuIuZJOzze",
        "outputId": "68e82132-554c-4995-9282-460414000b55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    lemmatized_text = [lemmatizer.lemmatize(word) for word in filtered_text]\n",
        "\n",
        "    cleaned_text = \" \".join(lemmatized_text)\n",
        "\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "-TNZ3ubtQNY9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [clean_text(phrase) for phrase in og_data]"
      ],
      "metadata": {
        "id": "PVkln9EWSJVt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check data integrity\n",
        "***don't run this***"
      ],
      "metadata": {
        "id": "1VTuArThTp90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for original, cleaned in zip(og_data[14:20], data[14:20]):\n",
        "    print(f\"Original: {original}\\nCleaned: {cleaned}\\n---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAnQ9vu0SQaC",
        "outputId": "a4aaa915-2f71-4fec-8a58-90f983ed49ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: Yeah , but what if it is not ? What if there is a reason why we can not have a baby ?\n",
            "Cleaned: yeah reason baby\n",
            "---\n",
            "Original: Oh , Chandler , look . You and Monica are meant to have children . I am sure it is gonna be just fine .\n",
            "Cleaned: oh chandler look monica meant child sure gon na fine\n",
            "---\n",
            "Original: oh , oh , yeah , ok , thanks .\n",
            "Cleaned: oh oh yeah ok thanks\n",
            "---\n",
            "Original: I can not believe I did not even think of that .\n",
            "Cleaned: believe even think\n",
            "---\n",
            "Original: I guess I was just so worried about having to ... come here and do ... that ...\n",
            "Cleaned: guess worried come\n",
            "---\n",
            "Original: What , you can do it in the parking lot of a Taco Bell , but you can not do it at a doctor office ?\n",
            "Cleaned: parking lot taco bell doctor office\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data),len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huTSkgyYSdst",
        "outputId": "29822d64-be0d-4ccb-b603-6e4dcc616c08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10246 10246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbsUZV3BTsr1",
        "outputId": "6cf9835b-3133-4c39-9f46-fd7c2c8cbb2d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML stuff"
      ],
      "metadata": {
        "id": "z1BMnpb_UFPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1V3ET3EBUEL4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "cnRb-M_qUPmh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVC"
      ],
      "metadata": {
        "id": "RktDVOiwUtfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_classifier = SVC(kernel='linear')\n",
        "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear']}\n",
        "grid_search = GridSearchCV(svm_classifier, param_grid, refit=True, verbose=3, cv=3)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "#svm_classifier.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hl5qOcXMYNj8",
        "outputId": "b9e537ca-7878-444f-a84a-8eea78bc28d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "[CV 1/3] END .....C=0.1, gamma=1, kernel=linear;, score=0.465 total time=   2.2s\n",
            "[CV 2/3] END .....C=0.1, gamma=1, kernel=linear;, score=0.463 total time=   2.2s\n",
            "[CV 3/3] END .....C=0.1, gamma=1, kernel=linear;, score=0.461 total time=   2.5s\n",
            "[CV 1/3] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.465 total time=   2.1s\n",
            "[CV 2/3] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.463 total time=   2.1s\n",
            "[CV 3/3] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.461 total time=   2.1s\n",
            "[CV 1/3] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.465 total time=   2.2s\n",
            "[CV 2/3] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.463 total time=   2.6s\n",
            "[CV 3/3] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.461 total time=   2.1s\n",
            "[CV 1/3] END .C=0.1, gamma=0.001, kernel=linear;, score=0.465 total time=   2.1s\n",
            "[CV 2/3] END .C=0.1, gamma=0.001, kernel=linear;, score=0.463 total time=   2.1s\n",
            "[CV 3/3] END .C=0.1, gamma=0.001, kernel=linear;, score=0.461 total time=   2.1s\n",
            "[CV 1/3] END .......C=1, gamma=1, kernel=linear;, score=0.486 total time=   2.5s\n",
            "[CV 2/3] END .......C=1, gamma=1, kernel=linear;, score=0.499 total time=   2.4s\n",
            "[CV 3/3] END .......C=1, gamma=1, kernel=linear;, score=0.479 total time=   2.2s\n",
            "[CV 1/3] END .....C=1, gamma=0.1, kernel=linear;, score=0.486 total time=   2.3s\n",
            "[CV 2/3] END .....C=1, gamma=0.1, kernel=linear;, score=0.499 total time=   2.2s\n",
            "[CV 3/3] END .....C=1, gamma=0.1, kernel=linear;, score=0.479 total time=   2.4s\n",
            "[CV 1/3] END ....C=1, gamma=0.01, kernel=linear;, score=0.486 total time=   2.5s\n",
            "[CV 2/3] END ....C=1, gamma=0.01, kernel=linear;, score=0.499 total time=   2.2s\n",
            "[CV 3/3] END ....C=1, gamma=0.01, kernel=linear;, score=0.479 total time=   3.0s\n",
            "[CV 1/3] END ...C=1, gamma=0.001, kernel=linear;, score=0.486 total time=   2.3s\n",
            "[CV 2/3] END ...C=1, gamma=0.001, kernel=linear;, score=0.499 total time=   2.5s\n",
            "[CV 3/3] END ...C=1, gamma=0.001, kernel=linear;, score=0.479 total time=   2.3s\n",
            "[CV 1/3] END ......C=10, gamma=1, kernel=linear;, score=0.447 total time=   3.1s\n",
            "[CV 2/3] END ......C=10, gamma=1, kernel=linear;, score=0.453 total time=   3.2s\n",
            "[CV 3/3] END ......C=10, gamma=1, kernel=linear;, score=0.450 total time=   4.0s\n",
            "[CV 1/3] END ....C=10, gamma=0.1, kernel=linear;, score=0.447 total time=   3.2s\n",
            "[CV 2/3] END ....C=10, gamma=0.1, kernel=linear;, score=0.453 total time=   4.1s\n",
            "[CV 3/3] END ....C=10, gamma=0.1, kernel=linear;, score=0.450 total time=   3.7s\n",
            "[CV 1/3] END ...C=10, gamma=0.01, kernel=linear;, score=0.447 total time=   3.4s\n",
            "[CV 2/3] END ...C=10, gamma=0.01, kernel=linear;, score=0.453 total time=   3.2s\n",
            "[CV 3/3] END ...C=10, gamma=0.01, kernel=linear;, score=0.450 total time=   3.4s\n",
            "[CV 1/3] END ..C=10, gamma=0.001, kernel=linear;, score=0.447 total time=   3.7s\n",
            "[CV 2/3] END ..C=10, gamma=0.001, kernel=linear;, score=0.453 total time=   3.1s\n",
            "[CV 3/3] END ..C=10, gamma=0.001, kernel=linear;, score=0.450 total time=   3.4s\n",
            "[CV 1/3] END .....C=100, gamma=1, kernel=linear;, score=0.435 total time=   7.8s\n",
            "[CV 2/3] END .....C=100, gamma=1, kernel=linear;, score=0.432 total time=   9.3s\n",
            "[CV 3/3] END .....C=100, gamma=1, kernel=linear;, score=0.436 total time=   7.0s\n",
            "[CV 1/3] END ...C=100, gamma=0.1, kernel=linear;, score=0.435 total time=   7.8s\n",
            "[CV 2/3] END ...C=100, gamma=0.1, kernel=linear;, score=0.432 total time=   9.3s\n",
            "[CV 3/3] END ...C=100, gamma=0.1, kernel=linear;, score=0.436 total time=   7.0s\n",
            "[CV 1/3] END ..C=100, gamma=0.01, kernel=linear;, score=0.435 total time=   7.8s\n",
            "[CV 2/3] END ..C=100, gamma=0.01, kernel=linear;, score=0.432 total time=   9.4s\n",
            "[CV 3/3] END ..C=100, gamma=0.01, kernel=linear;, score=0.436 total time=   7.1s\n",
            "[CV 1/3] END .C=100, gamma=0.001, kernel=linear;, score=0.435 total time=   7.8s\n",
            "[CV 2/3] END .C=100, gamma=0.001, kernel=linear;, score=0.432 total time=   9.4s\n",
            "[CV 3/3] END .C=100, gamma=0.001, kernel=linear;, score=0.436 total time=   7.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=SVC(kernel='linear'),\n",
              "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
              "                         'kernel': ['linear']},\n",
              "             verbose=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
              "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=SVC(kernel=&#x27;linear&#x27;),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
              "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap00dq7JUWL7",
        "outputId": "6e9b99f8-626d-4894-db61-b017569e3af3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_search.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "CrwJvDxqUaVY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "VpBJORDVYQRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea634e7e-52f8-4488-ee2f-08bb52ff3d76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.92      0.64       907\n",
            "           1       0.57      0.27      0.36       341\n",
            "           2       0.66      0.29      0.40       265\n",
            "           3       0.57      0.06      0.11        63\n",
            "           4       0.36      0.08      0.13       168\n",
            "           5       0.43      0.09      0.15       257\n",
            "           6       0.00      0.00      0.00        49\n",
            "\n",
            "    accuracy                           0.51      2050\n",
            "   macro avg       0.44      0.24      0.26      2050\n",
            "weighted avg       0.50      0.51      0.43      2050\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "xxDnuDqrUwAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier()\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]}\n",
        "grid_search = GridSearchCV(rf_classifier, param_grid, refit=True, verbose=3, cv=3)\n",
        "grid_search.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7iLFZI-0UxtH",
        "outputId": "92285606-231e-4880-ee4a-532efff5a64c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.471 total time=   6.1s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.469 total time=   6.0s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.462 total time=   5.4s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.471 total time=  11.4s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.469 total time=  11.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.467 total time=  11.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.469 total time=  22.8s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.470 total time=  23.1s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.465 total time=  23.1s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.473 total time=   4.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.470 total time=   4.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.465 total time=   4.1s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.474 total time=   8.8s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.474 total time=   9.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.472 total time=   8.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.475 total time=  17.7s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.477 total time=  17.0s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.471 total time=  17.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.475 total time=   3.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.476 total time=   3.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.466 total time=   4.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.474 total time=   7.1s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.474 total time=   7.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.467 total time=   7.8s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.477 total time=  14.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.474 total time=  14.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.471 total time=  15.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.482 total time=   3.1s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.493 total time=   2.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.474 total time=   2.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.480 total time=   5.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.488 total time=   5.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.477 total time=   5.0s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.483 total time=  10.4s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.489 total time=  10.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.474 total time=  10.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.480 total time=   2.4s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.486 total time=   2.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.474 total time=   3.1s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.483 total time=   4.7s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.494 total time=   5.1s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.472 total time=   5.4s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.485 total time=   9.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.489 total time=  10.4s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.477 total time=   9.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.478 total time=   2.8s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.488 total time=   2.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.475 total time=   2.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.484 total time=   4.8s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.489 total time=   5.0s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.475 total time=   4.7s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.481 total time=   9.7s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.486 total time=  10.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.475 total time=   9.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.477 total time=   1.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.485 total time=   1.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.474 total time=   1.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.477 total time=   2.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.489 total time=   3.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.476 total time=   2.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.476 total time=   5.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.488 total time=   6.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.473 total time=   5.4s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.479 total time=   2.1s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.484 total time=   1.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.473 total time=   1.4s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.478 total time=   3.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.489 total time=   2.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.472 total time=   3.4s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.478 total time=   5.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.489 total time=   7.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.474 total time=   5.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.479 total time=   1.4s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.489 total time=   1.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.475 total time=   1.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.478 total time=   2.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.493 total time=   3.1s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.475 total time=   2.8s\n",
            "[CV 1/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.478 total time=   6.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.486 total time=   5.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.471 total time=   6.2s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.438 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.8s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.8s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.1s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.1s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.1s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.435 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.1s\n",
            "[CV 2/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.1s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.445 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.436 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.443 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.451 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.443 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.445 total time=   1.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.437 total time=   3.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.448 total time=   2.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.455 total time=   2.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.441 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.450 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.451 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.451 total time=   1.2s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.446 total time=   1.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.448 total time=   1.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.446 total time=   2.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.445 total time=   2.4s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.446 total time=   2.3s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.455 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.451 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.441 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.448 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.440 total time=   1.7s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.437 total time=   1.1s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.447 total time=   2.2s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.439 total time=   2.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.451 total time=   2.2s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.439 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.448 total time=   0.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.439 total time=   0.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.437 total time=   1.2s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.445 total time=   1.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.437 total time=   1.0s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.444 total time=   1.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.442 total time=   1.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.437 total time=   1.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.441 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.441 total time=   0.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.441 total time=   0.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.445 total time=   1.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.444 total time=   1.1s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.450 total time=   1.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.436 total time=   2.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.437 total time=   1.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.442 total time=   1.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.450 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.445 total time=   0.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.437 total time=   0.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.437 total time=   1.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.440 total time=   1.0s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.448 total time=   1.0s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.442 total time=   2.6s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.438 total time=   1.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.441 total time=   1.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.445 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.441 total time=   0.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.447 total time=   0.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.440 total time=   1.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.435 total time=   1.0s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.444 total time=   0.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.436 total time=   2.3s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.435 total time=   2.2s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.444 total time=   1.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.445 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.437 total time=   0.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.440 total time=   0.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.437 total time=   0.9s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.439 total time=   0.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.440 total time=   1.0s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.436 total time=   1.8s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.441 total time=   2.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.437 total time=   1.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.453 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.439 total time=   0.5s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.438 total time=   0.5s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.441 total time=   1.0s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.440 total time=   0.9s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.452 total time=   0.9s\n",
            "[CV 1/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.442 total time=   1.8s\n",
            "[CV 2/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.440 total time=   1.8s\n",
            "[CV 3/3] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.437 total time=   2.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.458 total time=   8.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.456 total time=   9.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.450 total time=   9.3s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.459 total time=  17.6s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.455 total time=  18.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.451 total time=  17.9s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.466 total time=  35.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.457 total time=  36.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.452 total time=  37.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.465 total time=   6.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.459 total time=   7.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.451 total time=   6.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.469 total time=  13.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.461 total time=  14.6s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.452 total time=  14.0s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.469 total time=  27.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.462 total time=  27.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.454 total time=  28.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.464 total time=   5.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.460 total time=   6.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.456 total time=   5.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.469 total time=  12.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.461 total time=  12.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.457 total time=  12.1s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.469 total time=  23.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.464 total time=  24.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.461 total time=  24.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.475 total time=   4.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.481 total time=   4.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.465 total time=   4.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.476 total time=   8.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.481 total time=   8.9s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.462 total time=   8.9s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.476 total time=  16.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.480 total time=  18.0s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.464 total time=  17.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.477 total time=   3.9s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.478 total time=   4.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.466 total time=   4.2s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.476 total time=   8.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.483 total time=   8.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.464 total time=   8.2s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.475 total time=  17.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.480 total time=  17.0s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.465 total time=  17.9s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.477 total time=   3.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.475 total time=   3.9s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.463 total time=   4.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.474 total time=   7.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.479 total time=   8.5s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.461 total time=   8.6s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.479 total time=  16.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.481 total time=  17.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.461 total time=  16.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.476 total time=   3.0s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.486 total time=   3.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.473 total time=   3.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.481 total time=   5.9s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.491 total time=   7.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.472 total time=   6.2s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.478 total time=  12.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.490 total time=  13.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.474 total time=  13.2s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.481 total time=   3.0s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.490 total time=   3.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.473 total time=   3.1s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.480 total time=   6.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.492 total time=   6.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.470 total time=   6.3s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.480 total time=  12.9s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.491 total time=  13.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.471 total time=  12.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.477 total time=   3.6s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.492 total time=   3.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.470 total time=   3.0s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.482 total time=   6.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.491 total time=   6.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.470 total time=   6.6s\n",
            "[CV 1/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.477 total time=  12.6s\n",
            "[CV 2/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.489 total time=  13.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.472 total time=  12.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.436 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.435 total time=   0.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.434 total time=   2.2s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.434 total time=   2.0s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.6s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.6s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.6s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.434 total time=   2.2s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.5s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.435 total time=   0.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.5s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.5s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.6s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.435 total time=   0.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.434 total time=   1.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.434 total time=   1.2s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.5s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.5s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.435 total time=   1.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.435 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.5s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.435 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.435 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.435 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.434 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.434 total time=   1.0s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.434 total time=   1.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.435 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.434 total time=   1.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.435 total time=   1.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.434 total time=   0.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.436 total time=   0.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.435 total time=   0.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.434 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.434 total time=   1.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.443 total time=   0.9s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.441 total time=   0.9s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.440 total time=   1.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.453 total time=   1.9s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.450 total time=   1.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.447 total time=   1.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.445 total time=   3.5s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.445 total time=   4.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.449 total time=   3.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.452 total time=   0.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.444 total time=   0.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=0.450 total time=   0.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.448 total time=   1.6s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.447 total time=   1.6s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.452 total time=   2.2s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.448 total time=   3.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.446 total time=   3.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.449 total time=   3.1s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.439 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.455 total time=   1.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=0.452 total time=   1.1s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.446 total time=   1.4s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.447 total time=   1.5s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.452 total time=   1.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.450 total time=   3.0s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.449 total time=   3.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=0.445 total time=   3.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.455 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.449 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50;, score=0.449 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.447 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.442 total time=   1.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.446 total time=   1.4s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.437 total time=   3.2s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.442 total time=   2.9s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.444 total time=   2.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.448 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.445 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=0.449 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.443 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.440 total time=   1.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.450 total time=   2.0s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.440 total time=   2.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.447 total time=   2.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.447 total time=   2.6s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.436 total time=   0.6s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.443 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=0.441 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.444 total time=   2.0s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.442 total time=   1.4s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.451 total time=   1.3s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.440 total time=   2.8s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.436 total time=   2.6s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.443 total time=   2.8s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.438 total time=   1.0s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.448 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50;, score=0.440 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.450 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.436 total time=   1.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.446 total time=   1.3s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.440 total time=   2.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.446 total time=   2.8s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.441 total time=   3.1s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.447 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.445 total time=   0.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50;, score=0.455 total time=   0.6s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.439 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.439 total time=   1.3s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100;, score=0.454 total time=   1.3s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.441 total time=   2.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.437 total time=   3.1s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200;, score=0.447 total time=   2.5s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.442 total time=   0.7s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.453 total time=   0.6s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50;, score=0.442 total time=   0.7s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.439 total time=   1.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.440 total time=   1.2s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.443 total time=   1.3s\n",
            "[CV 1/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.436 total time=   3.3s\n",
            "[CV 2/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.443 total time=   2.7s\n",
            "[CV 3/3] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200;, score=0.438 total time=   2.6s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
              "             param_grid={'bootstrap': [True, False],\n",
              "                         'max_depth': [None, 10, 20],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5, 10],\n",
              "                         'n_estimators': [50, 100, 200]},\n",
              "             verbose=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
              "                         &#x27;max_depth&#x27;: [None, 10, 20],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
              "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;bootstrap&#x27;: [True, False],\n",
              "                         &#x27;max_depth&#x27;: [None, 10, 20],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
              "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E4r6t_0VARN",
        "outputId": "2f57f3c4-7d66-4662-d551-de3b607039ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid_search.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "Ld_t8DZEcxrO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8_oLTRUc0iN",
        "outputId": "6786a77c-d7f0-4532-8ce1-a86e526db28f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.89      0.64       907\n",
            "           1       0.53      0.27      0.36       341\n",
            "           2       0.54      0.35      0.43       265\n",
            "           3       0.33      0.02      0.03        63\n",
            "           4       0.36      0.08      0.13       168\n",
            "           5       0.37      0.09      0.14       257\n",
            "           6       0.00      0.00      0.00        49\n",
            "\n",
            "    accuracy                           0.50      2050\n",
            "   macro avg       0.38      0.24      0.25      2050\n",
            "weighted avg       0.47      0.50      0.43      2050\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN LSTM"
      ],
      "metadata": {
        "id": "KfRbEBzEc4pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "-iq20xBmc2cd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(data)"
      ],
      "metadata": {
        "id": "4Cw48Hdwc821"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "sHziseW_dAju"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(data)"
      ],
      "metadata": {
        "id": "OV5nIYGUdCWG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100"
      ],
      "metadata": {
        "id": "fZypMobpdD92"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "ssJ8WRWmdGum"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)"
      ],
      "metadata": {
        "id": "Zf05thq8dIfH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XMqsC-PSdKvQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 50  # Choose an appropriate embedding dimension\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length),\n",
        "    tf.keras.layers.LSTM(100),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')  # Adjust the number of units based on your number of classes\n",
        "])"
      ],
      "metadata": {
        "id": "8FSJlT3kdM69"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kZcsoSmEdRyO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RpL1_GpdVHt",
        "outputId": "069479da-babf-4dc9-d279-e1af3108606a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "257/257 [==============================] - 16s 48ms/step - loss: 1.6168 - accuracy: 0.4340 - val_loss: 1.5894 - val_accuracy: 0.4424\n",
            "Epoch 2/5\n",
            "257/257 [==============================] - 4s 14ms/step - loss: 1.6032 - accuracy: 0.4340 - val_loss: 1.5916 - val_accuracy: 0.4424\n",
            "Epoch 3/5\n",
            "257/257 [==============================] - 3s 12ms/step - loss: 1.6030 - accuracy: 0.4340 - val_loss: 1.5906 - val_accuracy: 0.4424\n",
            "Epoch 4/5\n",
            "257/257 [==============================] - 2s 9ms/step - loss: 1.6031 - accuracy: 0.4340 - val_loss: 1.5899 - val_accuracy: 0.4424\n",
            "Epoch 5/5\n",
            "257/257 [==============================] - 2s 8ms/step - loss: 1.6024 - accuracy: 0.4340 - val_loss: 1.5918 - val_accuracy: 0.4424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ac2c9ac9fc0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred_probabilities = model.predict(X_test)\n",
        "y_pred = tf.argmax(y_pred_probabilities, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbX-akJjdZcv",
        "outputId": "1fbd19e3-9428-4fe3-eee1-bc21ee82b0fb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK 2 ⚡\n",
        "\n"
      ],
      "metadata": {
        "id": "1X8EO6-Tg3jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install datasets"
      ],
      "metadata": {
        "id": "PP6L90YZlWJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BartForConditionalGeneration, BartTokenizer, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from datasets import load_metric\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TjWOi7qClFtZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_json_and_create_dataframes(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    utterance_rows = []\n",
        "    pair_rows = []\n",
        "    full_convo_texts = {}\n",
        "    full_convo_texts_tagged = {}\n",
        "\n",
        "    for conversation_id, conversation in data['conversation'].items():\n",
        "        full_convo_texts[conversation_id] = \"\"\n",
        "        full_convo_texts_tagged[conversation_id] = \"\"\n",
        "\n",
        "        for utterance in conversation:\n",
        "            full_convo_texts[conversation_id] += utterance[\"text\"] + \" \"\n",
        "            full_convo_texts_tagged[conversation_id] += f\"{utterance['utterance_ID']}_{utterance['text']} \"\n",
        "\n",
        "            utterance_row = {\n",
        "                \"conversation_id\": conversation_id,\n",
        "                \"utterance_id\": utterance[\"utterance_ID\"],\n",
        "                \"speaker\": utterance[\"speaker\"],\n",
        "                \"emotion\": utterance[\"emotion\"],\n",
        "                \"text\": utterance[\"text\"]\n",
        "            }\n",
        "            utterance_rows.append(utterance_row)\n",
        "\n",
        "        if conversation_id in data['emotion-cause_pairs']:\n",
        "            for pair in data['emotion-cause_pairs'][conversation_id]:\n",
        "                emotion_id, cause_text = pair\n",
        "                utterance_id, emotion = emotion_id.split(\"_\")\n",
        "                pair_row = {\n",
        "                    \"conversation_id\": conversation_id,\n",
        "                    \"emotion_utterance_id\": utterance_id,\n",
        "                    \"cause_text\": cause_text\n",
        "                }\n",
        "                pair_rows.append(pair_row)\n",
        "\n",
        "    df_utterances = pd.DataFrame(utterance_rows)\n",
        "    df_pairs = pd.DataFrame(pair_rows)\n",
        "\n",
        "    df_full_convos = pd.DataFrame(list(full_convo_texts.items()), columns=['conversation_id', 'full_conversation'])\n",
        "    df_full_convos_tagged = pd.DataFrame(list(full_convo_texts_tagged.items()), columns=['conversation_id', 'full_conversation_tagged'])\n",
        "\n",
        "    df_utterances['utterance_id'] = df_utterances['utterance_id'].astype(str)\n",
        "    df_pairs['emotion_utterance_id'] = df_pairs['emotion_utterance_id'].astype(str)\n",
        "\n",
        "    df_merged = pd.merge(df_utterances, df_pairs, how='left', left_on=['conversation_id', 'utterance_id'], right_on=['conversation_id', 'emotion_utterance_id'], suffixes=('', '_pair'))\n",
        "    df_final = pd.merge(df_merged, df_full_convos, on='conversation_id', how='left')\n",
        "    df_final = pd.merge(df_final, df_full_convos_tagged, on='conversation_id', how='left')\n",
        "\n",
        "    df_final['cause_text'] = df_final['cause_text'].fillna('')\n",
        "\n",
        "    df_final = df_final.drop(columns=['emotion_utterance_id'])\n",
        "\n",
        "    return df_final"
      ],
      "metadata": {
        "id": "ZDurrNf0DLL8"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/train_dataset.json'\n",
        "file_path_test = '/content/test_dataset.json'\n",
        "\n",
        "df_conversations = read_json_and_create_dataframes(file_path)\n",
        "df_test_conversations = read_json_and_create_dataframes(file_path_test)"
      ],
      "metadata": {
        "id": "o5tT7iIGDQNu"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionCauseDatasetQA_BERT(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        full_conversation = row['full_conversation']\n",
        "        text = f\"{row['utterance_id']}_{row['text']}\"\n",
        "        cause_text = row['cause_text'] if pd.notnull(row['cause_text']) else \"\"\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            f\"{full_conversation} [SEP] {text} [SEP] \",\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze()\n",
        "        attention_mask = inputs['attention_mask'].squeeze()\n",
        "        labels = torch.tensor(1 if cause_text else 0, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }"
      ],
      "metadata": {
        "id": "xtCzBRUSDT0Q"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmotionCauseDatasetBART(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        full_conversation = row['full_conversation']\n",
        "        target_phrase = f\"{row['utterance_id']}_{row['text']}\"\n",
        "        cause_text = f\"<EMOTION>{row['utterance_id']}_{row['emotion']}<CAUSE>{row['cause_text']}\" if pd.notnull(row['cause_text']) else '<NO_CAUSE>'\n",
        "\n",
        "        prompt = f\"Given the following conversation where each phrase is labeled with its ID: {full_conversation}. Considering the specific statement: '{target_phrase}', with its emotion, identify and label the part of the conversation that likely caused this emotion.\"\n",
        "\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
        "        targets = self.tokenizer(cause_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=self.max_length)\n",
        "\n",
        "        input_ids = inputs[\"input_ids\"].squeeze()\n",
        "        attention_mask = inputs[\"attention_mask\"].squeeze()\n",
        "        labels = targets[\"input_ids\"].squeeze()\n",
        "        labels[labels == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }"
      ],
      "metadata": {
        "id": "KS7w2EdLDYas"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bart_model(model, dataloader, device, epochs=2):\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item()}\")\n",
        "\n",
        "        avg_train_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1}, Average Loss: {avg_train_loss}\")\n",
        "\n",
        "def safe_decode_predictions(token_ids, tokenizer):\n",
        "    token_ids = token_ids[token_ids != -100]\n",
        "    return tokenizer.decode(token_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
      ],
      "metadata": {
        "id": "-Gg5mo7WDdlc"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictions_on_id(predictions, true_labels):\n",
        "    def extract_id(text):\n",
        "        id_end_index = text.find('_')\n",
        "        if id_end_index != -1:\n",
        "            return text[:id_end_index].strip()\n",
        "        return ''\n",
        "\n",
        "    correct_count = 0\n",
        "    total_count = len(predictions)\n",
        "\n",
        "    for pred, true in zip(predictions, true_labels):\n",
        "        pred_id = extract_id(pred)\n",
        "        true_id = extract_id(true)\n",
        "\n",
        "        if pred_id == true_id:\n",
        "            correct_count += 1\n",
        "\n",
        "    accuracy = correct_count / total_count if total_count > 0 else 0\n",
        "    print(f\"Accuracy based on ID comparison: {accuracy:.4f} ({correct_count}/{total_count})\")"
      ],
      "metadata": {
        "id": "EHctGcFSDhAV"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bart_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "\n",
        "        outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "        pred_texts = [safe_decode_predictions(g, tokenizer) for g in outputs]\n",
        "        true_texts = [safe_decode_predictions(t.cpu().numpy(), tokenizer) for t in batch['labels']]\n",
        "\n",
        "        predictions.extend(pred_texts)\n",
        "        true_labels.extend(true_texts)\n",
        "\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            print(f\"Evaluating Batch {batch_idx+1}/{len(dataloader)}\")\n",
        "    exact_matches = sum([1 for pred, true in zip(predictions, true_labels) if pred == true])\n",
        "    exact_match_rate = exact_matches / len(predictions)\n",
        "    print(f\"Exact Match Rate: {exact_match_rate}\")\n",
        "    evaluate_predictions_on_id(predictions, true_labels)"
      ],
      "metadata": {
        "id": "RnGHO-_0DkXa"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_bart = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "tokenizer_bart = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "model_bart.to(device)\n",
        "\n",
        "train_dataset_bart = EmotionCauseDatasetBART(df_conversations, tokenizer_bart)\n",
        "train_dataloader_bart = DataLoader(train_dataset_bart, batch_size=4, shuffle=True)\n",
        "\n",
        "test_dataset_bart = EmotionCauseDatasetBART(df_test_conversations, tokenizer_bart)\n",
        "test_dataloader_bart = DataLoader(test_dataset_bart, batch_size=4)\n",
        "\n",
        "# Train and evaluate\n",
        "train_bart_model(model_bart, train_dataloader_bart, device, epochs=2)\n",
        "evaluate_bart_model(model_bart, test_dataloader_bart, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrGvqTYaDnfs",
        "outputId": "6ff04efb-c040-4807-8bc5-48231f1a6465"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 10/3056, Loss: 1.401691198348999\n",
            "Epoch 1, Batch 20/3056, Loss: 0.6228248476982117\n",
            "Epoch 1, Batch 30/3056, Loss: 0.5766474008560181\n",
            "Epoch 1, Batch 40/3056, Loss: 0.6674779057502747\n",
            "Epoch 1, Batch 50/3056, Loss: 0.6233906149864197\n",
            "Epoch 1, Batch 60/3056, Loss: 0.35687586665153503\n",
            "Epoch 1, Batch 70/3056, Loss: 0.409392774105072\n",
            "Epoch 1, Batch 80/3056, Loss: 0.08458410948514938\n",
            "Epoch 1, Batch 90/3056, Loss: 0.5095883011817932\n",
            "Epoch 1, Batch 100/3056, Loss: 0.2792995572090149\n",
            "Epoch 1, Batch 110/3056, Loss: 0.23057983815670013\n",
            "Epoch 1, Batch 120/3056, Loss: 0.33956968784332275\n",
            "Epoch 1, Batch 130/3056, Loss: 0.2817486524581909\n",
            "Epoch 1, Batch 140/3056, Loss: 0.3259899318218231\n",
            "Epoch 1, Batch 150/3056, Loss: 0.6772845983505249\n",
            "Epoch 1, Batch 160/3056, Loss: 0.1391163468360901\n",
            "Epoch 1, Batch 170/3056, Loss: 0.17441587150096893\n",
            "Epoch 1, Batch 180/3056, Loss: 0.42194464802742004\n",
            "Epoch 1, Batch 190/3056, Loss: 0.26048049330711365\n",
            "Epoch 1, Batch 200/3056, Loss: 0.485975980758667\n",
            "Epoch 1, Batch 210/3056, Loss: 0.29780659079551697\n",
            "Epoch 1, Batch 220/3056, Loss: 0.1270647644996643\n",
            "Epoch 1, Batch 230/3056, Loss: 0.322806715965271\n",
            "Epoch 1, Batch 240/3056, Loss: 0.39337465167045593\n",
            "Epoch 1, Batch 250/3056, Loss: 0.3043535053730011\n",
            "Epoch 1, Batch 260/3056, Loss: 0.2714926600456238\n",
            "Epoch 1, Batch 270/3056, Loss: 0.27381473779678345\n",
            "Epoch 1, Batch 280/3056, Loss: 0.5060924291610718\n",
            "Epoch 1, Batch 290/3056, Loss: 0.4057314991950989\n",
            "Epoch 1, Batch 300/3056, Loss: 0.6503788232803345\n",
            "Epoch 1, Batch 310/3056, Loss: 0.45731911063194275\n",
            "Epoch 1, Batch 320/3056, Loss: 0.29404985904693604\n",
            "Epoch 1, Batch 330/3056, Loss: 0.4026435911655426\n",
            "Epoch 1, Batch 340/3056, Loss: 0.31927645206451416\n",
            "Epoch 1, Batch 350/3056, Loss: 0.28145721554756165\n",
            "Epoch 1, Batch 360/3056, Loss: 0.5671555399894714\n",
            "Epoch 1, Batch 370/3056, Loss: 0.23359298706054688\n",
            "Epoch 1, Batch 380/3056, Loss: 0.6642208099365234\n",
            "Epoch 1, Batch 390/3056, Loss: 0.41780319809913635\n",
            "Epoch 1, Batch 400/3056, Loss: 0.5173230171203613\n",
            "Epoch 1, Batch 410/3056, Loss: 0.3016214370727539\n",
            "Epoch 1, Batch 420/3056, Loss: 0.3500382602214813\n",
            "Epoch 1, Batch 430/3056, Loss: 0.421799898147583\n",
            "Epoch 1, Batch 440/3056, Loss: 0.2735801339149475\n",
            "Epoch 1, Batch 450/3056, Loss: 0.26317960023880005\n",
            "Epoch 1, Batch 460/3056, Loss: 0.2700970470905304\n",
            "Epoch 1, Batch 470/3056, Loss: 0.16151778399944305\n",
            "Epoch 1, Batch 480/3056, Loss: 0.31739845871925354\n",
            "Epoch 1, Batch 490/3056, Loss: 0.25424396991729736\n",
            "Epoch 1, Batch 500/3056, Loss: 0.15300391614437103\n",
            "Epoch 1, Batch 510/3056, Loss: 0.31888899207115173\n",
            "Epoch 1, Batch 520/3056, Loss: 0.42497894167900085\n",
            "Epoch 1, Batch 530/3056, Loss: 0.2950872480869293\n",
            "Epoch 1, Batch 540/3056, Loss: 0.4500727653503418\n",
            "Epoch 1, Batch 550/3056, Loss: 0.30197006464004517\n",
            "Epoch 1, Batch 560/3056, Loss: 0.4665152430534363\n",
            "Epoch 1, Batch 570/3056, Loss: 0.24344444274902344\n",
            "Epoch 1, Batch 580/3056, Loss: 0.35867929458618164\n",
            "Epoch 1, Batch 590/3056, Loss: 0.18453888595104218\n",
            "Epoch 1, Batch 600/3056, Loss: 0.41262131929397583\n",
            "Epoch 1, Batch 610/3056, Loss: 0.12896651029586792\n",
            "Epoch 1, Batch 620/3056, Loss: 0.34885135293006897\n",
            "Epoch 1, Batch 630/3056, Loss: 0.3664397895336151\n",
            "Epoch 1, Batch 640/3056, Loss: 0.17993636429309845\n",
            "Epoch 1, Batch 650/3056, Loss: 0.21652372181415558\n",
            "Epoch 1, Batch 660/3056, Loss: 0.24976418912410736\n",
            "Epoch 1, Batch 670/3056, Loss: 0.2272111475467682\n",
            "Epoch 1, Batch 680/3056, Loss: 0.3246523141860962\n",
            "Epoch 1, Batch 690/3056, Loss: 0.5064060091972351\n",
            "Epoch 1, Batch 700/3056, Loss: 0.22112330794334412\n",
            "Epoch 1, Batch 710/3056, Loss: 0.1372891217470169\n",
            "Epoch 1, Batch 720/3056, Loss: 0.34955698251724243\n",
            "Epoch 1, Batch 730/3056, Loss: 0.20944595336914062\n",
            "Epoch 1, Batch 740/3056, Loss: 0.1615583598613739\n",
            "Epoch 1, Batch 750/3056, Loss: 0.3373792767524719\n",
            "Epoch 1, Batch 760/3056, Loss: 0.5257682204246521\n",
            "Epoch 1, Batch 770/3056, Loss: 0.34233176708221436\n",
            "Epoch 1, Batch 780/3056, Loss: 0.4864729940891266\n",
            "Epoch 1, Batch 790/3056, Loss: 0.14571504294872284\n",
            "Epoch 1, Batch 800/3056, Loss: 0.39769530296325684\n",
            "Epoch 1, Batch 810/3056, Loss: 0.2980027198791504\n",
            "Epoch 1, Batch 820/3056, Loss: 0.3789249062538147\n",
            "Epoch 1, Batch 830/3056, Loss: 0.33465856313705444\n",
            "Epoch 1, Batch 840/3056, Loss: 0.3940652906894684\n",
            "Epoch 1, Batch 850/3056, Loss: 0.06646271049976349\n",
            "Epoch 1, Batch 860/3056, Loss: 0.2428165078163147\n",
            "Epoch 1, Batch 870/3056, Loss: 0.4157976508140564\n",
            "Epoch 1, Batch 880/3056, Loss: 0.23346847295761108\n",
            "Epoch 1, Batch 890/3056, Loss: 0.15556584298610687\n",
            "Epoch 1, Batch 900/3056, Loss: 0.2277808040380478\n",
            "Epoch 1, Batch 910/3056, Loss: 0.09853863716125488\n",
            "Epoch 1, Batch 920/3056, Loss: 0.23752079904079437\n",
            "Epoch 1, Batch 930/3056, Loss: 0.1891777068376541\n",
            "Epoch 1, Batch 940/3056, Loss: 0.45673227310180664\n",
            "Epoch 1, Batch 950/3056, Loss: 0.2956196069717407\n",
            "Epoch 1, Batch 960/3056, Loss: 0.4148046672344208\n",
            "Epoch 1, Batch 970/3056, Loss: 0.18275988101959229\n",
            "Epoch 1, Batch 980/3056, Loss: 0.536539614200592\n",
            "Epoch 1, Batch 990/3056, Loss: 0.18192164599895477\n",
            "Epoch 1, Batch 1000/3056, Loss: 0.26130545139312744\n",
            "Epoch 1, Batch 1010/3056, Loss: 0.2125450074672699\n",
            "Epoch 1, Batch 1020/3056, Loss: 0.16220152378082275\n",
            "Epoch 1, Batch 1030/3056, Loss: 0.2647610008716583\n",
            "Epoch 1, Batch 1040/3056, Loss: 0.3639979064464569\n",
            "Epoch 1, Batch 1050/3056, Loss: 0.28301480412483215\n",
            "Epoch 1, Batch 1060/3056, Loss: 0.22609290480613708\n",
            "Epoch 1, Batch 1070/3056, Loss: 0.32896146178245544\n",
            "Epoch 1, Batch 1080/3056, Loss: 0.22333821654319763\n",
            "Epoch 1, Batch 1090/3056, Loss: 0.5193670392036438\n",
            "Epoch 1, Batch 1100/3056, Loss: 0.1819477677345276\n",
            "Epoch 1, Batch 1110/3056, Loss: 0.27495625615119934\n",
            "Epoch 1, Batch 1120/3056, Loss: 0.22748281061649323\n",
            "Epoch 1, Batch 1130/3056, Loss: 0.30257779359817505\n",
            "Epoch 1, Batch 1140/3056, Loss: 0.29578763246536255\n",
            "Epoch 1, Batch 1150/3056, Loss: 0.1104537844657898\n",
            "Epoch 1, Batch 1160/3056, Loss: 0.357540100812912\n",
            "Epoch 1, Batch 1170/3056, Loss: 0.45027169585227966\n",
            "Epoch 1, Batch 1180/3056, Loss: 0.26264646649360657\n",
            "Epoch 1, Batch 1190/3056, Loss: 0.13813164830207825\n",
            "Epoch 1, Batch 1200/3056, Loss: 0.09500803798437119\n",
            "Epoch 1, Batch 1210/3056, Loss: 0.2851220667362213\n",
            "Epoch 1, Batch 1220/3056, Loss: 0.30846914649009705\n",
            "Epoch 1, Batch 1230/3056, Loss: 0.17751677334308624\n",
            "Epoch 1, Batch 1240/3056, Loss: 0.3150096833705902\n",
            "Epoch 1, Batch 1250/3056, Loss: 1.4553581476211548\n",
            "Epoch 1, Batch 1260/3056, Loss: 0.6039726734161377\n",
            "Epoch 1, Batch 1270/3056, Loss: 0.6019084453582764\n",
            "Epoch 1, Batch 1280/3056, Loss: 0.42895665764808655\n",
            "Epoch 1, Batch 1290/3056, Loss: 0.16093219816684723\n",
            "Epoch 1, Batch 1300/3056, Loss: 0.22468896210193634\n",
            "Epoch 1, Batch 1310/3056, Loss: 0.3986329138278961\n",
            "Epoch 1, Batch 1320/3056, Loss: 0.26679426431655884\n",
            "Epoch 1, Batch 1330/3056, Loss: 0.5488948822021484\n",
            "Epoch 1, Batch 1340/3056, Loss: 0.16136708855628967\n",
            "Epoch 1, Batch 1350/3056, Loss: 0.33755165338516235\n",
            "Epoch 1, Batch 1360/3056, Loss: 0.2885173261165619\n",
            "Epoch 1, Batch 1370/3056, Loss: 0.5820568203926086\n",
            "Epoch 1, Batch 1380/3056, Loss: 0.11143051832914352\n",
            "Epoch 1, Batch 1390/3056, Loss: 0.2261992245912552\n",
            "Epoch 1, Batch 1400/3056, Loss: 0.31210336089134216\n",
            "Epoch 1, Batch 1410/3056, Loss: 0.37664249539375305\n",
            "Epoch 1, Batch 1420/3056, Loss: 0.3037349283695221\n",
            "Epoch 1, Batch 1430/3056, Loss: 0.1286548376083374\n",
            "Epoch 1, Batch 1440/3056, Loss: 0.1719035506248474\n",
            "Epoch 1, Batch 1450/3056, Loss: 0.15300697088241577\n",
            "Epoch 1, Batch 1460/3056, Loss: 0.33460646867752075\n",
            "Epoch 1, Batch 1470/3056, Loss: 0.6470975875854492\n",
            "Epoch 1, Batch 1480/3056, Loss: 0.17099927365779877\n",
            "Epoch 1, Batch 1490/3056, Loss: 0.2781435549259186\n",
            "Epoch 1, Batch 1500/3056, Loss: 0.2589263319969177\n",
            "Epoch 1, Batch 1510/3056, Loss: 0.35615918040275574\n",
            "Epoch 1, Batch 1520/3056, Loss: 0.3640134036540985\n",
            "Epoch 1, Batch 1530/3056, Loss: 0.3987801969051361\n",
            "Epoch 1, Batch 1540/3056, Loss: 0.21136058866977692\n",
            "Epoch 1, Batch 1550/3056, Loss: 0.1951991766691208\n",
            "Epoch 1, Batch 1560/3056, Loss: 0.5328152775764465\n",
            "Epoch 1, Batch 1570/3056, Loss: 0.6708198189735413\n",
            "Epoch 1, Batch 1580/3056, Loss: 0.461031436920166\n",
            "Epoch 1, Batch 1590/3056, Loss: 0.2892186641693115\n",
            "Epoch 1, Batch 1600/3056, Loss: 0.20913557708263397\n",
            "Epoch 1, Batch 1610/3056, Loss: 0.1945144087076187\n",
            "Epoch 1, Batch 1620/3056, Loss: 0.3912329375743866\n",
            "Epoch 1, Batch 1630/3056, Loss: 0.19991369545459747\n",
            "Epoch 1, Batch 1640/3056, Loss: 0.28412914276123047\n",
            "Epoch 1, Batch 1650/3056, Loss: 0.11394254863262177\n",
            "Epoch 1, Batch 1660/3056, Loss: 0.20838512480258942\n",
            "Epoch 1, Batch 1670/3056, Loss: 0.2940329313278198\n",
            "Epoch 1, Batch 1680/3056, Loss: 0.28625577688217163\n",
            "Epoch 1, Batch 1690/3056, Loss: 0.1319456249475479\n",
            "Epoch 1, Batch 1700/3056, Loss: 0.17508770525455475\n",
            "Epoch 1, Batch 1710/3056, Loss: 0.1935393065214157\n",
            "Epoch 1, Batch 1720/3056, Loss: 0.43928343057632446\n",
            "Epoch 1, Batch 1730/3056, Loss: 0.34550741314888\n",
            "Epoch 1, Batch 1740/3056, Loss: 0.3044688105583191\n",
            "Epoch 1, Batch 1750/3056, Loss: 0.2058197557926178\n",
            "Epoch 1, Batch 1760/3056, Loss: 0.23880493640899658\n",
            "Epoch 1, Batch 1770/3056, Loss: 0.20293328166007996\n",
            "Epoch 1, Batch 1780/3056, Loss: 0.267841100692749\n",
            "Epoch 1, Batch 1790/3056, Loss: 0.18537357449531555\n",
            "Epoch 1, Batch 1800/3056, Loss: 0.24645423889160156\n",
            "Epoch 1, Batch 1810/3056, Loss: 0.4155283272266388\n",
            "Epoch 1, Batch 1820/3056, Loss: 0.2642943561077118\n",
            "Epoch 1, Batch 1830/3056, Loss: 0.13260860741138458\n",
            "Epoch 1, Batch 1840/3056, Loss: 0.3210117816925049\n",
            "Epoch 1, Batch 1850/3056, Loss: 0.20614421367645264\n",
            "Epoch 1, Batch 1860/3056, Loss: 0.4610137343406677\n",
            "Epoch 1, Batch 1870/3056, Loss: 0.1962326020002365\n",
            "Epoch 1, Batch 1880/3056, Loss: 0.07722657173871994\n",
            "Epoch 1, Batch 1890/3056, Loss: 0.29604482650756836\n",
            "Epoch 1, Batch 1900/3056, Loss: 0.21654295921325684\n",
            "Epoch 1, Batch 1910/3056, Loss: 0.12360825389623642\n",
            "Epoch 1, Batch 1920/3056, Loss: 0.12382902950048447\n",
            "Epoch 1, Batch 1930/3056, Loss: 0.12179231643676758\n",
            "Epoch 1, Batch 1940/3056, Loss: 0.22649632394313812\n",
            "Epoch 1, Batch 1950/3056, Loss: 0.20126746594905853\n",
            "Epoch 1, Batch 1960/3056, Loss: 0.13276249170303345\n",
            "Epoch 1, Batch 1970/3056, Loss: 0.24180668592453003\n",
            "Epoch 1, Batch 1980/3056, Loss: 0.24444545805454254\n",
            "Epoch 1, Batch 1990/3056, Loss: 0.10566706210374832\n",
            "Epoch 1, Batch 2000/3056, Loss: 0.24176862835884094\n",
            "Epoch 1, Batch 2010/3056, Loss: 0.503836989402771\n",
            "Epoch 1, Batch 2020/3056, Loss: 0.21467022597789764\n",
            "Epoch 1, Batch 2030/3056, Loss: 0.17149586975574493\n",
            "Epoch 1, Batch 2040/3056, Loss: 0.17024829983711243\n",
            "Epoch 1, Batch 2050/3056, Loss: 0.2410535365343094\n",
            "Epoch 1, Batch 2060/3056, Loss: 0.40562188625335693\n",
            "Epoch 1, Batch 2070/3056, Loss: 0.28208187222480774\n",
            "Epoch 1, Batch 2080/3056, Loss: 0.10122275352478027\n",
            "Epoch 1, Batch 2090/3056, Loss: 0.26809754967689514\n",
            "Epoch 1, Batch 2100/3056, Loss: 0.2842145562171936\n",
            "Epoch 1, Batch 2110/3056, Loss: 0.15664604306221008\n",
            "Epoch 1, Batch 2120/3056, Loss: 0.10233569145202637\n",
            "Epoch 1, Batch 2130/3056, Loss: 0.37569302320480347\n",
            "Epoch 1, Batch 2140/3056, Loss: 0.06405941396951675\n",
            "Epoch 1, Batch 2150/3056, Loss: 0.027728138491511345\n",
            "Epoch 1, Batch 2160/3056, Loss: 0.2405260056257248\n",
            "Epoch 1, Batch 2170/3056, Loss: 0.23636357486248016\n",
            "Epoch 1, Batch 2180/3056, Loss: 0.3091219365596771\n",
            "Epoch 1, Batch 2190/3056, Loss: 0.12373499572277069\n",
            "Epoch 1, Batch 2200/3056, Loss: 0.16993148624897003\n",
            "Epoch 1, Batch 2210/3056, Loss: 0.19663386046886444\n",
            "Epoch 1, Batch 2220/3056, Loss: 0.23420868813991547\n",
            "Epoch 1, Batch 2230/3056, Loss: 0.4326540231704712\n",
            "Epoch 1, Batch 2240/3056, Loss: 0.16684797406196594\n",
            "Epoch 1, Batch 2250/3056, Loss: 0.3825405538082123\n",
            "Epoch 1, Batch 2260/3056, Loss: 0.30964022874832153\n",
            "Epoch 1, Batch 2270/3056, Loss: 0.25450819730758667\n",
            "Epoch 1, Batch 2280/3056, Loss: 0.26245757937431335\n",
            "Epoch 1, Batch 2290/3056, Loss: 0.19011223316192627\n",
            "Epoch 1, Batch 2300/3056, Loss: 0.15611569583415985\n",
            "Epoch 1, Batch 2310/3056, Loss: 0.18915896117687225\n",
            "Epoch 1, Batch 2320/3056, Loss: 0.41516244411468506\n",
            "Epoch 1, Batch 2330/3056, Loss: 0.18886427581310272\n",
            "Epoch 1, Batch 2340/3056, Loss: 0.3421723544597626\n",
            "Epoch 1, Batch 2350/3056, Loss: 0.340597540140152\n",
            "Epoch 1, Batch 2360/3056, Loss: 0.34953591227531433\n",
            "Epoch 1, Batch 2370/3056, Loss: 0.18776291608810425\n",
            "Epoch 1, Batch 2380/3056, Loss: 0.09111837297677994\n",
            "Epoch 1, Batch 2390/3056, Loss: 0.11819911003112793\n",
            "Epoch 1, Batch 2400/3056, Loss: 0.4814838469028473\n",
            "Epoch 1, Batch 2410/3056, Loss: 0.19876626133918762\n",
            "Epoch 1, Batch 2420/3056, Loss: 0.28079500794410706\n",
            "Epoch 1, Batch 2430/3056, Loss: 0.17683584988117218\n",
            "Epoch 1, Batch 2440/3056, Loss: 0.13820435106754303\n",
            "Epoch 1, Batch 2450/3056, Loss: 0.1298290640115738\n",
            "Epoch 1, Batch 2460/3056, Loss: 0.3081527352333069\n",
            "Epoch 1, Batch 2470/3056, Loss: 0.20108334720134735\n",
            "Epoch 1, Batch 2480/3056, Loss: 0.24055184423923492\n",
            "Epoch 1, Batch 2490/3056, Loss: 0.27483442425727844\n",
            "Epoch 1, Batch 2500/3056, Loss: 0.2943265438079834\n",
            "Epoch 1, Batch 2510/3056, Loss: 0.22489766776561737\n",
            "Epoch 1, Batch 2520/3056, Loss: 0.26423245668411255\n",
            "Epoch 1, Batch 2530/3056, Loss: 0.24175623059272766\n",
            "Epoch 1, Batch 2540/3056, Loss: 0.2616383135318756\n",
            "Epoch 1, Batch 2550/3056, Loss: 0.219991073012352\n",
            "Epoch 1, Batch 2560/3056, Loss: 0.31059756875038147\n",
            "Epoch 1, Batch 2570/3056, Loss: 0.20040154457092285\n",
            "Epoch 1, Batch 2580/3056, Loss: 0.14504915475845337\n",
            "Epoch 1, Batch 2590/3056, Loss: 0.1739496886730194\n",
            "Epoch 1, Batch 2600/3056, Loss: 0.19980008900165558\n",
            "Epoch 1, Batch 2610/3056, Loss: 0.23028069734573364\n",
            "Epoch 1, Batch 2620/3056, Loss: 0.16339583694934845\n",
            "Epoch 1, Batch 2630/3056, Loss: 0.16028890013694763\n",
            "Epoch 1, Batch 2640/3056, Loss: 0.38773831725120544\n",
            "Epoch 1, Batch 2650/3056, Loss: 0.7434569597244263\n",
            "Epoch 1, Batch 2660/3056, Loss: 0.08044485002756119\n",
            "Epoch 1, Batch 2670/3056, Loss: 0.20996423065662384\n",
            "Epoch 1, Batch 2680/3056, Loss: 0.16060850024223328\n",
            "Epoch 1, Batch 2690/3056, Loss: 0.3226657211780548\n",
            "Epoch 1, Batch 2700/3056, Loss: 0.27032676339149475\n",
            "Epoch 1, Batch 2710/3056, Loss: 0.07756192982196808\n",
            "Epoch 1, Batch 2720/3056, Loss: 0.1629061996936798\n",
            "Epoch 1, Batch 2730/3056, Loss: 0.15292805433273315\n",
            "Epoch 1, Batch 2740/3056, Loss: 0.17357251048088074\n",
            "Epoch 1, Batch 2750/3056, Loss: 0.09683119505643845\n",
            "Epoch 1, Batch 2760/3056, Loss: 0.2692868113517761\n",
            "Epoch 1, Batch 2770/3056, Loss: 0.3679533004760742\n",
            "Epoch 1, Batch 2780/3056, Loss: 0.289154589176178\n",
            "Epoch 1, Batch 2790/3056, Loss: 0.05464034155011177\n",
            "Epoch 1, Batch 2800/3056, Loss: 0.30247336626052856\n",
            "Epoch 1, Batch 2810/3056, Loss: 0.3899690508842468\n",
            "Epoch 1, Batch 2820/3056, Loss: 0.08992162346839905\n",
            "Epoch 1, Batch 2830/3056, Loss: 0.31468868255615234\n",
            "Epoch 1, Batch 2840/3056, Loss: 0.05526642128825188\n",
            "Epoch 1, Batch 2850/3056, Loss: 0.24117396771907806\n",
            "Epoch 1, Batch 2860/3056, Loss: 0.14186814427375793\n",
            "Epoch 1, Batch 2870/3056, Loss: 0.3382464647293091\n",
            "Epoch 1, Batch 2880/3056, Loss: 0.2614586055278778\n",
            "Epoch 1, Batch 2890/3056, Loss: 0.3808375895023346\n",
            "Epoch 1, Batch 2900/3056, Loss: 0.29978063702583313\n",
            "Epoch 1, Batch 2910/3056, Loss: 0.3555944561958313\n",
            "Epoch 1, Batch 2920/3056, Loss: 0.1889611929655075\n",
            "Epoch 1, Batch 2930/3056, Loss: 0.12776431441307068\n",
            "Epoch 1, Batch 2940/3056, Loss: 0.29932016134262085\n",
            "Epoch 1, Batch 2950/3056, Loss: 0.20347711443901062\n",
            "Epoch 1, Batch 2960/3056, Loss: 0.29842665791511536\n",
            "Epoch 1, Batch 2970/3056, Loss: 0.4925905466079712\n",
            "Epoch 1, Batch 2980/3056, Loss: 0.23880451917648315\n",
            "Epoch 1, Batch 2990/3056, Loss: 0.3426980674266815\n",
            "Epoch 1, Batch 3000/3056, Loss: 0.1345621645450592\n",
            "Epoch 1, Batch 3010/3056, Loss: 0.1309477686882019\n",
            "Epoch 1, Batch 3020/3056, Loss: 0.24119949340820312\n",
            "Epoch 1, Batch 3030/3056, Loss: 0.15357628464698792\n",
            "Epoch 1, Batch 3040/3056, Loss: 0.34242141246795654\n",
            "Epoch 1, Batch 3050/3056, Loss: 0.2661104202270508\n",
            "Epoch 1, Average Loss: 0.2996229755658509\n",
            "Epoch 2, Batch 10/3056, Loss: 0.20017176866531372\n",
            "Epoch 2, Batch 20/3056, Loss: 0.19343993067741394\n",
            "Epoch 2, Batch 30/3056, Loss: 0.1764131635427475\n",
            "Epoch 2, Batch 40/3056, Loss: 0.17379717528820038\n",
            "Epoch 2, Batch 50/3056, Loss: 0.2669680118560791\n",
            "Epoch 2, Batch 60/3056, Loss: 0.21341775357723236\n",
            "Epoch 2, Batch 70/3056, Loss: 0.22792142629623413\n",
            "Epoch 2, Batch 80/3056, Loss: 0.20413753390312195\n",
            "Epoch 2, Batch 90/3056, Loss: 0.38094547390937805\n",
            "Epoch 2, Batch 100/3056, Loss: 0.22737841308116913\n",
            "Epoch 2, Batch 110/3056, Loss: 0.08940698206424713\n",
            "Epoch 2, Batch 120/3056, Loss: 0.15473605692386627\n",
            "Epoch 2, Batch 130/3056, Loss: 0.2821429371833801\n",
            "Epoch 2, Batch 140/3056, Loss: 0.3943282663822174\n",
            "Epoch 2, Batch 150/3056, Loss: 0.2572300434112549\n",
            "Epoch 2, Batch 160/3056, Loss: 0.13298964500427246\n",
            "Epoch 2, Batch 170/3056, Loss: 0.23466534912586212\n",
            "Epoch 2, Batch 180/3056, Loss: 0.14986304938793182\n",
            "Epoch 2, Batch 190/3056, Loss: 0.20730678737163544\n",
            "Epoch 2, Batch 200/3056, Loss: 0.254606157541275\n",
            "Epoch 2, Batch 210/3056, Loss: 0.15726719796657562\n",
            "Epoch 2, Batch 220/3056, Loss: 0.05672723799943924\n",
            "Epoch 2, Batch 230/3056, Loss: 0.3838758170604706\n",
            "Epoch 2, Batch 240/3056, Loss: 0.10359746962785721\n",
            "Epoch 2, Batch 250/3056, Loss: 0.1640656441450119\n",
            "Epoch 2, Batch 260/3056, Loss: 0.2369023859500885\n",
            "Epoch 2, Batch 270/3056, Loss: 0.42396125197410583\n",
            "Epoch 2, Batch 280/3056, Loss: 0.2544667422771454\n",
            "Epoch 2, Batch 290/3056, Loss: 0.044768981635570526\n",
            "Epoch 2, Batch 300/3056, Loss: 0.1236642375588417\n",
            "Epoch 2, Batch 310/3056, Loss: 0.13080628216266632\n",
            "Epoch 2, Batch 320/3056, Loss: 0.49069976806640625\n",
            "Epoch 2, Batch 330/3056, Loss: 0.11787254363298416\n",
            "Epoch 2, Batch 340/3056, Loss: 0.28113695979118347\n",
            "Epoch 2, Batch 350/3056, Loss: 0.2398841381072998\n",
            "Epoch 2, Batch 360/3056, Loss: 0.15461784601211548\n",
            "Epoch 2, Batch 370/3056, Loss: 0.15380506217479706\n",
            "Epoch 2, Batch 380/3056, Loss: 0.2310624122619629\n",
            "Epoch 2, Batch 390/3056, Loss: 0.305366188287735\n",
            "Epoch 2, Batch 400/3056, Loss: 0.04503897204995155\n",
            "Epoch 2, Batch 410/3056, Loss: 0.15868841111660004\n",
            "Epoch 2, Batch 420/3056, Loss: 0.1760944128036499\n",
            "Epoch 2, Batch 430/3056, Loss: 0.24400940537452698\n",
            "Epoch 2, Batch 440/3056, Loss: 0.17442351579666138\n",
            "Epoch 2, Batch 450/3056, Loss: 0.17874005436897278\n",
            "Epoch 2, Batch 460/3056, Loss: 0.1643613874912262\n",
            "Epoch 2, Batch 470/3056, Loss: 0.3679256737232208\n",
            "Epoch 2, Batch 480/3056, Loss: 0.2968275249004364\n",
            "Epoch 2, Batch 490/3056, Loss: 0.1452893167734146\n",
            "Epoch 2, Batch 500/3056, Loss: 0.27851226925849915\n",
            "Epoch 2, Batch 510/3056, Loss: 0.31757310032844543\n",
            "Epoch 2, Batch 520/3056, Loss: 0.20423413813114166\n",
            "Epoch 2, Batch 530/3056, Loss: 0.22004278004169464\n",
            "Epoch 2, Batch 540/3056, Loss: 0.1356913298368454\n",
            "Epoch 2, Batch 550/3056, Loss: 0.2626150846481323\n",
            "Epoch 2, Batch 560/3056, Loss: 0.14386479556560516\n",
            "Epoch 2, Batch 570/3056, Loss: 0.17441847920417786\n",
            "Epoch 2, Batch 580/3056, Loss: 1.4963114261627197\n",
            "Epoch 2, Batch 590/3056, Loss: 0.2741962671279907\n",
            "Epoch 2, Batch 600/3056, Loss: 0.3116600513458252\n",
            "Epoch 2, Batch 610/3056, Loss: 0.18456719815731049\n",
            "Epoch 2, Batch 620/3056, Loss: 0.17038699984550476\n",
            "Epoch 2, Batch 630/3056, Loss: 0.2628215253353119\n",
            "Epoch 2, Batch 640/3056, Loss: 0.22281213104724884\n",
            "Epoch 2, Batch 650/3056, Loss: 0.07683520764112473\n",
            "Epoch 2, Batch 660/3056, Loss: 0.3104969263076782\n",
            "Epoch 2, Batch 670/3056, Loss: 0.24208542704582214\n",
            "Epoch 2, Batch 680/3056, Loss: 0.21472616493701935\n",
            "Epoch 2, Batch 690/3056, Loss: 0.09294217079877853\n",
            "Epoch 2, Batch 700/3056, Loss: 0.2851834297180176\n",
            "Epoch 2, Batch 710/3056, Loss: 0.13899223506450653\n",
            "Epoch 2, Batch 720/3056, Loss: 0.11575932055711746\n",
            "Epoch 2, Batch 730/3056, Loss: 0.36882853507995605\n",
            "Epoch 2, Batch 740/3056, Loss: 0.2529825270175934\n",
            "Epoch 2, Batch 750/3056, Loss: 0.10619501024484634\n",
            "Epoch 2, Batch 760/3056, Loss: 0.19799883663654327\n",
            "Epoch 2, Batch 770/3056, Loss: 0.28161895275115967\n",
            "Epoch 2, Batch 780/3056, Loss: 0.19493022561073303\n",
            "Epoch 2, Batch 790/3056, Loss: 0.1926812082529068\n",
            "Epoch 2, Batch 800/3056, Loss: 0.22486260533332825\n",
            "Epoch 2, Batch 810/3056, Loss: 0.19256620109081268\n",
            "Epoch 2, Batch 820/3056, Loss: 0.10873188823461533\n",
            "Epoch 2, Batch 830/3056, Loss: 0.28032103180885315\n",
            "Epoch 2, Batch 840/3056, Loss: 0.43972504138946533\n",
            "Epoch 2, Batch 850/3056, Loss: 0.28761470317840576\n",
            "Epoch 2, Batch 860/3056, Loss: 0.17216692864894867\n",
            "Epoch 2, Batch 870/3056, Loss: 0.02589167095720768\n",
            "Epoch 2, Batch 880/3056, Loss: 0.09411930292844772\n",
            "Epoch 2, Batch 890/3056, Loss: 0.17508037388324738\n",
            "Epoch 2, Batch 900/3056, Loss: 0.19065748155117035\n",
            "Epoch 2, Batch 910/3056, Loss: 0.09313026070594788\n",
            "Epoch 2, Batch 920/3056, Loss: 0.17416749894618988\n",
            "Epoch 2, Batch 930/3056, Loss: 0.14290234446525574\n",
            "Epoch 2, Batch 940/3056, Loss: 0.200283482670784\n",
            "Epoch 2, Batch 950/3056, Loss: 0.38194090127944946\n",
            "Epoch 2, Batch 960/3056, Loss: 0.1763068288564682\n",
            "Epoch 2, Batch 970/3056, Loss: 0.3643576204776764\n",
            "Epoch 2, Batch 980/3056, Loss: 0.10595759749412537\n",
            "Epoch 2, Batch 990/3056, Loss: 0.2839900255203247\n",
            "Epoch 2, Batch 1000/3056, Loss: 0.3823069930076599\n",
            "Epoch 2, Batch 1010/3056, Loss: 0.2166908234357834\n",
            "Epoch 2, Batch 1020/3056, Loss: 0.20689280331134796\n",
            "Epoch 2, Batch 1030/3056, Loss: 0.23130927979946136\n",
            "Epoch 2, Batch 1040/3056, Loss: 0.19738227128982544\n",
            "Epoch 2, Batch 1050/3056, Loss: 0.3467710614204407\n",
            "Epoch 2, Batch 1060/3056, Loss: 0.13753296434879303\n",
            "Epoch 2, Batch 1070/3056, Loss: 0.13301610946655273\n",
            "Epoch 2, Batch 1080/3056, Loss: 0.21978232264518738\n",
            "Epoch 2, Batch 1090/3056, Loss: 0.21908168494701385\n",
            "Epoch 2, Batch 1100/3056, Loss: 0.09420400857925415\n",
            "Epoch 2, Batch 1110/3056, Loss: 0.13724006712436676\n",
            "Epoch 2, Batch 1120/3056, Loss: 0.16495543718338013\n",
            "Epoch 2, Batch 1130/3056, Loss: 0.027482513338327408\n",
            "Epoch 2, Batch 1140/3056, Loss: 0.14285312592983246\n",
            "Epoch 2, Batch 1150/3056, Loss: 0.23679235577583313\n",
            "Epoch 2, Batch 1160/3056, Loss: 0.2867632210254669\n",
            "Epoch 2, Batch 1170/3056, Loss: 0.4498521089553833\n",
            "Epoch 2, Batch 1180/3056, Loss: 0.13207606971263885\n",
            "Epoch 2, Batch 1190/3056, Loss: 0.31075745820999146\n",
            "Epoch 2, Batch 1200/3056, Loss: 0.32805007696151733\n",
            "Epoch 2, Batch 1210/3056, Loss: 0.11121168732643127\n",
            "Epoch 2, Batch 1220/3056, Loss: 0.1960165649652481\n",
            "Epoch 2, Batch 1230/3056, Loss: 0.19623686373233795\n",
            "Epoch 2, Batch 1240/3056, Loss: 0.14537595212459564\n",
            "Epoch 2, Batch 1250/3056, Loss: 0.1835366040468216\n",
            "Epoch 2, Batch 1260/3056, Loss: 0.15141016244888306\n",
            "Epoch 2, Batch 1270/3056, Loss: 0.3002736568450928\n",
            "Epoch 2, Batch 1280/3056, Loss: 0.2851051390171051\n",
            "Epoch 2, Batch 1290/3056, Loss: 0.2971270978450775\n",
            "Epoch 2, Batch 1300/3056, Loss: 0.15908342599868774\n",
            "Epoch 2, Batch 1310/3056, Loss: 0.1451515257358551\n",
            "Epoch 2, Batch 1320/3056, Loss: 0.08205293118953705\n",
            "Epoch 2, Batch 1330/3056, Loss: 0.14175646007061005\n",
            "Epoch 2, Batch 1340/3056, Loss: 0.17344576120376587\n",
            "Epoch 2, Batch 1350/3056, Loss: 0.20743678510189056\n",
            "Epoch 2, Batch 1360/3056, Loss: 0.10951738059520721\n",
            "Epoch 2, Batch 1370/3056, Loss: 0.10515516251325607\n",
            "Epoch 2, Batch 1380/3056, Loss: 0.18179939687252045\n",
            "Epoch 2, Batch 1390/3056, Loss: 0.3676535189151764\n",
            "Epoch 2, Batch 1400/3056, Loss: 0.22571028769016266\n",
            "Epoch 2, Batch 1410/3056, Loss: 0.11104152351617813\n",
            "Epoch 2, Batch 1420/3056, Loss: 0.16278770565986633\n",
            "Epoch 2, Batch 1430/3056, Loss: 0.1548982411623001\n",
            "Epoch 2, Batch 1440/3056, Loss: 0.17501424252986908\n",
            "Epoch 2, Batch 1450/3056, Loss: 0.095407634973526\n",
            "Epoch 2, Batch 1460/3056, Loss: 0.3793877959251404\n",
            "Epoch 2, Batch 1470/3056, Loss: 0.23578865826129913\n",
            "Epoch 2, Batch 1480/3056, Loss: 0.11008746922016144\n",
            "Epoch 2, Batch 1490/3056, Loss: 0.21813516318798065\n",
            "Epoch 2, Batch 1500/3056, Loss: 0.16500966250896454\n",
            "Epoch 2, Batch 1510/3056, Loss: 0.1163615807890892\n",
            "Epoch 2, Batch 1520/3056, Loss: 0.24096298217773438\n",
            "Epoch 2, Batch 1530/3056, Loss: 0.09424411505460739\n",
            "Epoch 2, Batch 1540/3056, Loss: 0.3323633074760437\n",
            "Epoch 2, Batch 1550/3056, Loss: 0.1793447583913803\n",
            "Epoch 2, Batch 1560/3056, Loss: 0.18732117116451263\n",
            "Epoch 2, Batch 1570/3056, Loss: 0.2998204231262207\n",
            "Epoch 2, Batch 1580/3056, Loss: 0.3222387135028839\n",
            "Epoch 2, Batch 1590/3056, Loss: 0.10598857700824738\n",
            "Epoch 2, Batch 1600/3056, Loss: 0.24589981138706207\n",
            "Epoch 2, Batch 1610/3056, Loss: 0.1763557493686676\n",
            "Epoch 2, Batch 1620/3056, Loss: 0.07374174892902374\n",
            "Epoch 2, Batch 1630/3056, Loss: 0.15221266448497772\n",
            "Epoch 2, Batch 1640/3056, Loss: 0.2118992805480957\n",
            "Epoch 2, Batch 1650/3056, Loss: 0.09141413122415543\n",
            "Epoch 2, Batch 1660/3056, Loss: 0.07678873091936111\n",
            "Epoch 2, Batch 1670/3056, Loss: 0.1779993176460266\n",
            "Epoch 2, Batch 1680/3056, Loss: 0.15566939115524292\n",
            "Epoch 2, Batch 1690/3056, Loss: 0.1933014839887619\n",
            "Epoch 2, Batch 1700/3056, Loss: 0.05288784205913544\n",
            "Epoch 2, Batch 1710/3056, Loss: 0.18034909665584564\n",
            "Epoch 2, Batch 1720/3056, Loss: 0.0707550197839737\n",
            "Epoch 2, Batch 1730/3056, Loss: 0.12169216573238373\n",
            "Epoch 2, Batch 1740/3056, Loss: 0.27779126167297363\n",
            "Epoch 2, Batch 1750/3056, Loss: 0.21631263196468353\n",
            "Epoch 2, Batch 1760/3056, Loss: 0.18176737427711487\n",
            "Epoch 2, Batch 1770/3056, Loss: 0.6367740631103516\n",
            "Epoch 2, Batch 1780/3056, Loss: 0.11356192827224731\n",
            "Epoch 2, Batch 1790/3056, Loss: 0.28338223695755005\n",
            "Epoch 2, Batch 1800/3056, Loss: 0.3123340606689453\n",
            "Epoch 2, Batch 1810/3056, Loss: 0.25735998153686523\n",
            "Epoch 2, Batch 1820/3056, Loss: 0.21325372159481049\n",
            "Epoch 2, Batch 1830/3056, Loss: 0.13498175144195557\n",
            "Epoch 2, Batch 1840/3056, Loss: 0.22118546068668365\n",
            "Epoch 2, Batch 1850/3056, Loss: 0.1602240949869156\n",
            "Epoch 2, Batch 1860/3056, Loss: 0.1354074627161026\n",
            "Epoch 2, Batch 1870/3056, Loss: 0.16525313258171082\n",
            "Epoch 2, Batch 1880/3056, Loss: 0.20705105364322662\n",
            "Epoch 2, Batch 1890/3056, Loss: 0.3455624580383301\n",
            "Epoch 2, Batch 1900/3056, Loss: 0.1674240380525589\n",
            "Epoch 2, Batch 1910/3056, Loss: 0.2667570412158966\n",
            "Epoch 2, Batch 1920/3056, Loss: 0.31488165259361267\n",
            "Epoch 2, Batch 1930/3056, Loss: 0.11019427329301834\n",
            "Epoch 2, Batch 1940/3056, Loss: 0.1763678938150406\n",
            "Epoch 2, Batch 1950/3056, Loss: 0.5023999214172363\n",
            "Epoch 2, Batch 1960/3056, Loss: 0.20846489071846008\n",
            "Epoch 2, Batch 1970/3056, Loss: 0.1087675541639328\n",
            "Epoch 2, Batch 1980/3056, Loss: 0.26539456844329834\n",
            "Epoch 2, Batch 1990/3056, Loss: 0.06856907159090042\n",
            "Epoch 2, Batch 2000/3056, Loss: 0.1097211092710495\n",
            "Epoch 2, Batch 2010/3056, Loss: 0.17248618602752686\n",
            "Epoch 2, Batch 2020/3056, Loss: 0.27488934993743896\n",
            "Epoch 2, Batch 2030/3056, Loss: 0.18484266102313995\n",
            "Epoch 2, Batch 2040/3056, Loss: 0.1588614135980606\n",
            "Epoch 2, Batch 2050/3056, Loss: 0.1708156168460846\n",
            "Epoch 2, Batch 2060/3056, Loss: 0.2443082481622696\n",
            "Epoch 2, Batch 2070/3056, Loss: 0.0754178911447525\n",
            "Epoch 2, Batch 2080/3056, Loss: 0.16122689843177795\n",
            "Epoch 2, Batch 2090/3056, Loss: 0.14811088144779205\n",
            "Epoch 2, Batch 2100/3056, Loss: 0.07775481790304184\n",
            "Epoch 2, Batch 2110/3056, Loss: 0.24405065178871155\n",
            "Epoch 2, Batch 2120/3056, Loss: 0.2744533121585846\n",
            "Epoch 2, Batch 2130/3056, Loss: 0.2777266800403595\n",
            "Epoch 2, Batch 2140/3056, Loss: 0.3009330928325653\n",
            "Epoch 2, Batch 2150/3056, Loss: 0.1524980366230011\n",
            "Epoch 2, Batch 2160/3056, Loss: 0.08649197965860367\n",
            "Epoch 2, Batch 2170/3056, Loss: 0.1473914533853531\n",
            "Epoch 2, Batch 2180/3056, Loss: 0.12297206372022629\n",
            "Epoch 2, Batch 2190/3056, Loss: 0.28103160858154297\n",
            "Epoch 2, Batch 2200/3056, Loss: 0.08386452496051788\n",
            "Epoch 2, Batch 2210/3056, Loss: 0.10999039560556412\n",
            "Epoch 2, Batch 2220/3056, Loss: 0.15551921725273132\n",
            "Epoch 2, Batch 2230/3056, Loss: 0.3862221837043762\n",
            "Epoch 2, Batch 2240/3056, Loss: 0.19596922397613525\n",
            "Epoch 2, Batch 2250/3056, Loss: 0.06885527074337006\n",
            "Epoch 2, Batch 2260/3056, Loss: 0.20624960958957672\n",
            "Epoch 2, Batch 2270/3056, Loss: 0.28970015048980713\n",
            "Epoch 2, Batch 2280/3056, Loss: 0.13208092749118805\n",
            "Epoch 2, Batch 2290/3056, Loss: 0.13480083644390106\n",
            "Epoch 2, Batch 2300/3056, Loss: 0.2735308110713959\n",
            "Epoch 2, Batch 2310/3056, Loss: 0.382616251707077\n",
            "Epoch 2, Batch 2320/3056, Loss: 0.19449447095394135\n",
            "Epoch 2, Batch 2330/3056, Loss: 0.4239681363105774\n",
            "Epoch 2, Batch 2340/3056, Loss: 0.08432426303625107\n",
            "Epoch 2, Batch 2350/3056, Loss: 0.194414421916008\n",
            "Epoch 2, Batch 2360/3056, Loss: 0.2593783736228943\n",
            "Epoch 2, Batch 2370/3056, Loss: 0.25587359070777893\n",
            "Epoch 2, Batch 2380/3056, Loss: 0.25315478444099426\n",
            "Epoch 2, Batch 2390/3056, Loss: 0.15158315002918243\n",
            "Epoch 2, Batch 2400/3056, Loss: 0.14026618003845215\n",
            "Epoch 2, Batch 2410/3056, Loss: 0.12949532270431519\n",
            "Epoch 2, Batch 2420/3056, Loss: 0.27940210700035095\n",
            "Epoch 2, Batch 2430/3056, Loss: 0.12675148248672485\n",
            "Epoch 2, Batch 2440/3056, Loss: 0.3362342119216919\n",
            "Epoch 2, Batch 2450/3056, Loss: 0.3276575207710266\n",
            "Epoch 2, Batch 2460/3056, Loss: 0.23211300373077393\n",
            "Epoch 2, Batch 2470/3056, Loss: 0.2880071997642517\n",
            "Epoch 2, Batch 2480/3056, Loss: 0.333301842212677\n",
            "Epoch 2, Batch 2490/3056, Loss: 0.19704070687294006\n",
            "Epoch 2, Batch 2500/3056, Loss: 0.1695794314146042\n",
            "Epoch 2, Batch 2510/3056, Loss: 0.20001761615276337\n",
            "Epoch 2, Batch 2520/3056, Loss: 0.24885426461696625\n",
            "Epoch 2, Batch 2530/3056, Loss: 0.2856954038143158\n",
            "Epoch 2, Batch 2540/3056, Loss: 0.2883760929107666\n",
            "Epoch 2, Batch 2550/3056, Loss: 0.10335671901702881\n",
            "Epoch 2, Batch 2560/3056, Loss: 0.12010007351636887\n",
            "Epoch 2, Batch 2570/3056, Loss: 0.04522840678691864\n",
            "Epoch 2, Batch 2580/3056, Loss: 0.1460331380367279\n",
            "Epoch 2, Batch 2590/3056, Loss: 0.33274149894714355\n",
            "Epoch 2, Batch 2600/3056, Loss: 0.09648940712213516\n",
            "Epoch 2, Batch 2610/3056, Loss: 0.2871956527233124\n",
            "Epoch 2, Batch 2620/3056, Loss: 0.2103581428527832\n",
            "Epoch 2, Batch 2630/3056, Loss: 0.12702304124832153\n",
            "Epoch 2, Batch 2640/3056, Loss: 0.07535546272993088\n",
            "Epoch 2, Batch 2650/3056, Loss: 0.3188650906085968\n",
            "Epoch 2, Batch 2660/3056, Loss: 0.20572032034397125\n",
            "Epoch 2, Batch 2670/3056, Loss: 0.1852738857269287\n",
            "Epoch 2, Batch 2680/3056, Loss: 0.12290306389331818\n",
            "Epoch 2, Batch 2690/3056, Loss: 0.35084936022758484\n",
            "Epoch 2, Batch 2700/3056, Loss: 0.20317938923835754\n",
            "Epoch 2, Batch 2710/3056, Loss: 0.10105793178081512\n",
            "Epoch 2, Batch 2720/3056, Loss: 0.13548128306865692\n",
            "Epoch 2, Batch 2730/3056, Loss: 0.2540726959705353\n",
            "Epoch 2, Batch 2740/3056, Loss: 0.10455676168203354\n",
            "Epoch 2, Batch 2750/3056, Loss: 0.40788984298706055\n",
            "Epoch 2, Batch 2760/3056, Loss: 0.23359471559524536\n",
            "Epoch 2, Batch 2770/3056, Loss: 0.22388309240341187\n",
            "Epoch 2, Batch 2780/3056, Loss: 0.44104915857315063\n",
            "Epoch 2, Batch 2790/3056, Loss: 0.15251578390598297\n",
            "Epoch 2, Batch 2800/3056, Loss: 0.10223561525344849\n",
            "Epoch 2, Batch 2810/3056, Loss: 0.32019346952438354\n",
            "Epoch 2, Batch 2820/3056, Loss: 0.15437984466552734\n",
            "Epoch 2, Batch 2830/3056, Loss: 0.16804014146327972\n",
            "Epoch 2, Batch 2840/3056, Loss: 0.09348995238542557\n",
            "Epoch 2, Batch 2850/3056, Loss: 0.07385360449552536\n",
            "Epoch 2, Batch 2860/3056, Loss: 0.25295141339302063\n",
            "Epoch 2, Batch 2870/3056, Loss: 0.19762255251407623\n",
            "Epoch 2, Batch 2880/3056, Loss: 0.12336582690477371\n",
            "Epoch 2, Batch 2890/3056, Loss: 0.3607155382633209\n",
            "Epoch 2, Batch 2900/3056, Loss: 0.26091355085372925\n",
            "Epoch 2, Batch 2910/3056, Loss: 0.2594720125198364\n",
            "Epoch 2, Batch 2920/3056, Loss: 0.3150235116481781\n",
            "Epoch 2, Batch 2930/3056, Loss: 0.15602722764015198\n",
            "Epoch 2, Batch 2940/3056, Loss: 0.5204688906669617\n",
            "Epoch 2, Batch 2950/3056, Loss: 0.30253008008003235\n",
            "Epoch 2, Batch 2960/3056, Loss: 0.13940395414829254\n",
            "Epoch 2, Batch 2970/3056, Loss: 0.2622451186180115\n",
            "Epoch 2, Batch 2980/3056, Loss: 0.2764461934566498\n",
            "Epoch 2, Batch 2990/3056, Loss: 0.0755896344780922\n",
            "Epoch 2, Batch 3000/3056, Loss: 0.2554325461387634\n",
            "Epoch 2, Batch 3010/3056, Loss: 0.23832565546035767\n",
            "Epoch 2, Batch 3020/3056, Loss: 0.3759482204914093\n",
            "Epoch 2, Batch 3030/3056, Loss: 0.15597762167453766\n",
            "Epoch 2, Batch 3040/3056, Loss: 0.2955234944820404\n",
            "Epoch 2, Batch 3050/3056, Loss: 0.06237851828336716\n",
            "Epoch 2, Average Loss: 0.20521266340992428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Batch 10/1000\n",
            "Evaluating Batch 20/1000\n",
            "Evaluating Batch 30/1000\n",
            "Evaluating Batch 40/1000\n",
            "Evaluating Batch 50/1000\n",
            "Evaluating Batch 60/1000\n",
            "Evaluating Batch 70/1000\n",
            "Evaluating Batch 80/1000\n",
            "Evaluating Batch 90/1000\n",
            "Evaluating Batch 100/1000\n",
            "Evaluating Batch 110/1000\n",
            "Evaluating Batch 120/1000\n",
            "Evaluating Batch 130/1000\n",
            "Evaluating Batch 140/1000\n",
            "Evaluating Batch 150/1000\n",
            "Evaluating Batch 160/1000\n",
            "Evaluating Batch 170/1000\n",
            "Evaluating Batch 180/1000\n",
            "Evaluating Batch 190/1000\n",
            "Evaluating Batch 200/1000\n",
            "Evaluating Batch 210/1000\n",
            "Evaluating Batch 220/1000\n",
            "Evaluating Batch 230/1000\n",
            "Evaluating Batch 240/1000\n",
            "Evaluating Batch 250/1000\n",
            "Evaluating Batch 260/1000\n",
            "Evaluating Batch 270/1000\n",
            "Evaluating Batch 280/1000\n",
            "Evaluating Batch 290/1000\n",
            "Evaluating Batch 300/1000\n",
            "Evaluating Batch 310/1000\n",
            "Evaluating Batch 320/1000\n",
            "Evaluating Batch 330/1000\n",
            "Evaluating Batch 340/1000\n",
            "Evaluating Batch 350/1000\n",
            "Evaluating Batch 360/1000\n",
            "Evaluating Batch 370/1000\n",
            "Evaluating Batch 380/1000\n",
            "Evaluating Batch 390/1000\n",
            "Evaluating Batch 400/1000\n",
            "Evaluating Batch 410/1000\n",
            "Evaluating Batch 420/1000\n",
            "Evaluating Batch 430/1000\n",
            "Evaluating Batch 440/1000\n",
            "Evaluating Batch 450/1000\n",
            "Evaluating Batch 460/1000\n",
            "Evaluating Batch 470/1000\n",
            "Evaluating Batch 480/1000\n",
            "Evaluating Batch 490/1000\n",
            "Evaluating Batch 500/1000\n",
            "Evaluating Batch 510/1000\n",
            "Evaluating Batch 520/1000\n",
            "Evaluating Batch 530/1000\n",
            "Evaluating Batch 540/1000\n",
            "Evaluating Batch 550/1000\n",
            "Evaluating Batch 560/1000\n",
            "Evaluating Batch 570/1000\n",
            "Evaluating Batch 580/1000\n",
            "Evaluating Batch 590/1000\n",
            "Evaluating Batch 600/1000\n",
            "Evaluating Batch 610/1000\n",
            "Evaluating Batch 620/1000\n",
            "Evaluating Batch 630/1000\n",
            "Evaluating Batch 640/1000\n",
            "Evaluating Batch 650/1000\n",
            "Evaluating Batch 660/1000\n",
            "Evaluating Batch 670/1000\n",
            "Evaluating Batch 680/1000\n",
            "Evaluating Batch 690/1000\n",
            "Evaluating Batch 700/1000\n",
            "Evaluating Batch 710/1000\n",
            "Evaluating Batch 720/1000\n",
            "Evaluating Batch 730/1000\n",
            "Evaluating Batch 740/1000\n",
            "Evaluating Batch 750/1000\n",
            "Evaluating Batch 760/1000\n",
            "Evaluating Batch 770/1000\n",
            "Evaluating Batch 780/1000\n",
            "Evaluating Batch 790/1000\n",
            "Evaluating Batch 800/1000\n",
            "Evaluating Batch 810/1000\n",
            "Evaluating Batch 820/1000\n",
            "Evaluating Batch 830/1000\n",
            "Evaluating Batch 840/1000\n",
            "Evaluating Batch 850/1000\n",
            "Evaluating Batch 860/1000\n",
            "Evaluating Batch 870/1000\n",
            "Evaluating Batch 880/1000\n",
            "Evaluating Batch 890/1000\n",
            "Evaluating Batch 900/1000\n",
            "Evaluating Batch 910/1000\n",
            "Evaluating Batch 920/1000\n",
            "Evaluating Batch 930/1000\n",
            "Evaluating Batch 940/1000\n",
            "Evaluating Batch 950/1000\n",
            "Evaluating Batch 960/1000\n",
            "Evaluating Batch 970/1000\n",
            "Evaluating Batch 980/1000\n",
            "Evaluating Batch 990/1000\n",
            "Evaluating Batch 1000/1000\n",
            "Exact Match Rate: 0.35967983991996\n",
            "Accuracy based on ID comparison: 1.0000 (3998/3998)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mf4fJc6nBMqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}